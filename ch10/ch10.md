## Greedy Algorithm

- "Take what you can get now" strategy is the source of the name for this class of algorithm
- Virtually all scheduling problems are either NP-complete or are solvable by a greedy algorithm

### Huffman Codes

- If the characters are placed only at the leaves, any sequence of bits can always be decoded unambiguously
- Such an encoding is known as **prefix code**
- The encoding information must be transmitted at the start of the compressed file, since otherwise it will be impossible to decode
- This is a two-pass algorithm, the first pass collects the frequency data and the second pass does the encoding
- If we maintain the trees in a priority queue, ordered by weight, then the running time is `O(ClogC)`, where the `C` is the number of characters

### Approximate Bin Packing

#### Online Algorithm

- There are inputs that force any online bin-packing algorithm to use at least 4/3 the optimal number of bins
- **Next Fit**: When processing any items, we check to see whether it fits in the same bin as the last item. It it does, it is placed there; otherwise, a new bin is created
  - Let `M` be the optimal number of bins required to pack a list `I` of items. Then next fit never uses more than `2M` bins
- **First Fit**: Scan the bins in order and place the new item in the first bin that is large enough to hold it
  - Let `M` be the optimal number of bins required to pack a list `I` of items. Then next fit never uses more than `(17/10)M + 7/10` bins
- **Best Fit**: Instead of placing a new item in the first spot that is found, it is placed in the tightest spot among all bins
  - Let `M` be the optimal number of bins required to pack a list `I` of items. Then next fit never uses more than `(17/10)M` bins

#### Offline Algorithms

- The natural way around this is to sort the items, placing the largest items first. We can apply first fit or best fit, yielding the algorithms **first fit decreasing** and **best fit decreasing**, respectively. These 2 are almost identical
- Let `M` be the optimal number of bins required to pack a list `I` of items. Then first fit decreasing never uses more than `(4M + 1)/3` bins
  - Can be get by two lemma below:
    1. Let the `N` items have input sizes `s1,s2,...,sN`, respectively, and suppose that the optimal packing is `M` bins. Then all items that first fit decreasing places in extra bins have size at most 1/3
    2. The number of objects placed in extra bins is at most `M - 1`
- Let `M` be the optimal number of bins required to pack a list `I` of items. Then first fit decreasing never uses more than `(11/9)M + 6/9` bins
- In practice, first fit decreasing performs extremely well
- Bin packing is a fine example of how simple greedy heuristics can give good results

## Divide and Conquer

- We generally insist that the subproblems be disjoint (that is, essentially nonoverlapping)

### Running Time

- The solution to the equation `T(N) = aT(N/b) + O(N^k)`, where `a >= 1` and `b > 1`, is
  - `T(N) = O(N^(logb(a))` if `a > b^k`
  - `T(N) = O((N^k)logN)` if `a = b^k`
  - `T(N) = O(N^k)` if `a < b^k`

### Closest-Points Problem

- A list `P` of points in a plane. We are required to find the closest pair of points

- Algorithm steps:
  - Sort the points based on their x coordinate, and also sort the points based on their y coordinate
  - **Divide**: Recursively divide the plane into half, then we can easily get the closest pair in each plane
  - **Conquer**: We need to combine 2 plane together. The difficult is to calculate the closest pair across 2 plane. Can consider the method below:
    - We only need to consider the points around the boundary, we assume the cloest distance on these 2 plane is `c`. eg. for each point `a(x1,y1)`, we only need to consider other points which `x1 - c <= x <= x1 + c` and `y1 - c <= y <= y1 + c`. At most 7 points points are considered. So the whole process only take `O(N)` time since we also sort the points base on their y coordinate on another list
  - This strategy ensures that the entire algorithm is `O(NlogN)`

### The Selection Problem

- The selection problem requires us to find the kth smallest element in a collection `S` of `N` elements
- Previous we use quick selection to make the average complexity to `O(N)`, but the worst case still `O(N^2)`. Of particular interest is the special case of finding the median
- Instead of finding the median from a sample of random elements, we will find the median from a **sample of median** - **median-of-median-of-five partitioning**
- The running time of quickselect using median-of-median-of-five partitioning is `O(N)` because this algorithm can ensure the recursive call can contain at most 0.7 * N elements

## Dynamic Programming

- By rewriting the recursive algorithm as a nonrecursive algorithm that systematically records answers to the subproblems in a table
- It is essentially the divide-and-conquer paradigm of solving simpler problems first, with the importan difference being that the simpler problems are not a clear division of the original

### Ordering Matrix Multiplications

- We define `M(L,R)` to be the number of multiplication required in an optimal ordering, then
`M(L,R) = min(M(L,i) + M(i+1,R) + c(L-1) * ci * c(R))`

```java
public static void optMatrix(int[] c, long[][] m, int[][] lastChange) {
  int n = c.length - 1;

  for (int left = 1; left <= n; left++) {
    m[left][left] = 0;
  }

  for (int k = 1; k < n; k++) { // k = right - left
    for (int left = 1; left <= n - k; left++) {
      // for each position
      int right = left + k;
      m[left][right] = INFINITY;
      for (int i = left; i < right; i++) {
        long thisCost = m[left][i] + m[i + 1][right] + c[left - 1] * c[i] * c[right];
        if (thisCost < m[left][right]) { // update min
          m[left][right] = thisCost;
          lastChange[left][right] = i;
        }
      }
    }
  }
}
```

### Optimal Binary Search Tree

- Given a list of words, `w1,w2,...,wN` and **fixed** probabilities `p1,p2,...,pN` of their occurrence. The problem is to arrange these words in a binary search tree in a way that minimizes the expected total access time

- The problem can be express in formula `C(L,R) = min(C(L,i) + C(i+1,R) + SUM(pj))`

### All-Pairs Shortest Path

- We define `D(k,i,j)` to be the weight of the shortest path from `vi` to `vj` that uses only `v1,v2,...,vk` as intermediates. We can get formula `D(k,i,j) = min(D(k-1,i,j),D(k-1,i,k)+D(k-1,k,j))`

```java
// Using k as an intermediate vertex on a path that starts or finishes with k nodes
// does not improve the result unless there is a negative cycle, so
// D(k-1,i,k) = D(k,i,k), D(k-1,k,j) = D(k,k,j)

// Then, We can only use one 2d matrix instead of 3d
public static void allPairs(int[][] a, int[][] d, int[][] path) {
  int n = a.length;

  for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
      d[i][j] = a[i][j];
      path[i][j] = NOT_A_VERTEX;
    }
  }

  for (int k = 0; k < n; k++) {
    for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
        if (d[i][k] + d[k][j] < d[i][j]) {
          d[i][j] = d[i][k] + d[k][j];
          path[i][j] = k;
        }
      }
    }
  }
}
```

## Randomized Algorithms

### Random Number Generators

- Generally, it suffices to produce **pseudorandom** numbers, which are numbers that appear to be random

- The simplest method to generate random numbers is the **linear congruential generator**. Numbers `x1,x2,...` are generated satisfying `xi+1 = A * xi mod M`. To start the sequence, some value of `x0` must be given. This value is known as the **seed**

- Random class design to avoid overflow:
```java
public class Random {
  private static final int A = 48271;
  private static final int M = 2147483647;
  private static final int Q = M / A;
  private static final int R = M % A;

  public int randomInt() {
    int tmpState = A * (state % Q) - R * (state / Q);

    if (tmpState >= 0) {
      state = tmpState;
    } else {
      state = tmpState + M;
    }

    return state;
  }
}
```

- Linear congruential generators are unsuitable for some applications, such as cryptography or in simulations that require large numbers of highly independent and uncorrelated random numbers. In those cases, the Java class **java.security.SecureRandom** should be used
