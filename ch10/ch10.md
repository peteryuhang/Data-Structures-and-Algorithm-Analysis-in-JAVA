## Greedy Algorithm

- "Take what you can get now" strategy is the source of the name for this class of algorithm
- Virtually all scheduling problems are either NP-complete or are solvable by a greedy algorithm

### Huffman Codes

- If the characters are placed only at the leaves, any sequence of bits can always be decoded unambiguously
- Such an encoding is known as **prefix code**
- The encoding information must be transmitted at the start of the compressed file, since otherwise it will be impossible to decode
- This is a two-pass algorithm, the first pass collects the frequency data and the second pass does the encoding
- If we maintain the trees in a priority queue, ordered by weight, then the running time is `O(ClogC)`, where the `C` is the number of characters

### Approximate Bin Packing

#### Online Algorithm

- There are inputs that force any online bin-packing algorithm to use at least 4/3 the optimal number of bins
- **Next Fit**: When processing any items, we check to see whether it fits in the same bin as the last item. It it does, it is placed there; otherwise, a new bin is created
  - Let `M` be the optimal number of bins required to pack a list `I` of items. Then next fit never uses more than `2M` bins
- **First Fit**: Scan the bins in order and place the new item in the first bin that is large enough to hold it
  - Let `M` be the optimal number of bins required to pack a list `I` of items. Then next fit never uses more than `(17/10)M + 7/10` bins
- **Best Fit**: Instead of placing a new item in the first spot that is found, it is placed in the tightest spot among all bins
  - Let `M` be the optimal number of bins required to pack a list `I` of items. Then next fit never uses more than `(17/10)M` bins

#### Offline Algorithms

- The natural way around this is to sort the items, placing the largest items first. We can apply first fit or best fit, yielding the algorithms **first fit decreasing** and **best fit decreasing**, respectively. These 2 are almost identical
- Let `M` be the optimal number of bins required to pack a list `I` of items. Then first fit decreasing never uses more than `(4M + 1)/3` bins
  - Can be get by two lemma below:
    1. Let the `N` items have input sizes `s1,s2,...,sN`, respectively, and suppose that the optimal packing is `M` bins. Then all items that first fit decreasing places in extra bins have size at most 1/3
    2. The number of objects placed in extra bins is at most `M - 1`
- Let `M` be the optimal number of bins required to pack a list `I` of items. Then first fit decreasing never uses more than `(11/9)M + 6/9` bins
- In practice, first fit decreasing performs extremely well
- Bin packing is a fine example of how simple greedy heuristics can give good results

## Divide and Conquer

- We generally insist that the subproblems be disjoint (that is, essentially nonoverlapping)

### Running Time

- The solution to the equation `T(N) = aT(N/b) + O(N^k)`, where `a >= 1` and `b > 1`, is
  - `T(N) = O(N^(logb(a))` if `a > b^k`
  - `T(N) = O((N^k)logN)` if `a = b^k`
  - `T(N) = O(N^k)` if `a < b^k`

### Closest-Points Problem

- A list `P` of points in a plane. We are required to find the closest pair of points

- Algorithm steps:
  - Sort the points based on their x coordinate, and also sort the points based on their y coordinate
  - **Divide**: Recursively divide the plane into half, then we can easily get the closest pair in each plane
  - **Conquer**: We need to combine 2 plane together. The difficult is to calculate the closest pair across 2 plane. Can consider the method below:
    - We only need to consider the points around the boundary, we assume the cloest distance on these 2 plane is `c`. eg. for each point `a(x1,y1)`, we only need to consider other points which `x1 - c <= x <= x1 + c` and `y1 - c <= y <= y1 + c`. At most 7 points points are considered. So the whole process only take `O(N)` time since we also sort the points base on their y coordinate on another list
  - This strategy ensures that the entire algorithm is `O(NlogN)`

